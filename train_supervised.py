import os
import shutil # å¼•å…¥ shutil ç”¨äºæ–‡ä»¶ç§»åŠ¨
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import matplotlib.pyplot as plt

# ==========================================
# 1. é…ç½®
# ==========================================
CLASS_NAMES = [
    'tracking_dance', 'tracking_fallandgetup', 'tracking_fight', 
    'tracking_gesture', 'tracking_ground', 'tracking_jump', 
    'tracking_obstacle', 'tracking_pose', 'tracking_push', 
    'tracking_run', 'tracking_sit', 'tracking_sprint', 
    'tracking_throw', 'tracking_treadmill', 'tracking_turn', 
    'tracking_vehicle', 'tracking_walk'
]
LABEL_MAP = {name: i for i, name in enumerate(CLASS_NAMES)}

# --- æ ¸å¿ƒä¿®æ”¹åŒº ---
MAX_ROUNDS = 30          # æ”¹æˆ 30 è½®ï¼ä¸æ¬ç©ºä¸ç½¢ä¼‘
EPOCHS_PER_ROUND = 10    # æ¯è½®è®­ç»ƒæ¬¡æ•°ç¨å¾®å‡å°‘ä¸€ç‚¹ï¼ŒåŠ å¿«è¿­ä»£é€Ÿåº¦
BATCH_SIZE = 64
SEQ_LEN = 60

# åŠ¨æ€é˜ˆå€¼ç­–ç•¥ï¼šä» 0.95 æ…¢æ…¢é™åˆ° 0.80ï¼Œä¿è¯æœ€åèƒ½æ”¶åº•
START_CONF = 0.95
END_CONF = 0.80

# ==========================================
# 2. æ•°æ®é›†ç±»
# ==========================================
class MemoryDataset(Dataset):
    def __init__(self, data_list, seq_len=60):
        self.seq_len = seq_len
        self.data = data_list

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        file_path = item['path']
        label = item['label']
        
        try:
            with np.load(file_path, allow_pickle=True) as data:
                best_arr = None
                max_len = 0
                for k in data.files:
                    arr = data[k]
                    if hasattr(arr, 'ndim') and arr.ndim == 2 and np.issubdtype(arr.dtype, np.number):
                        if arr.shape[0] > max_len and arr.shape[1] > 10:
                            max_len = arr.shape[0]
                            best_arr = arr
                
                if best_arr is None:
                    return torch.zeros((self.seq_len, 72), dtype=torch.float32), label
                
                if best_arr.shape[1] >= 72: clip = best_arr[:, :72]
                else: clip = np.hstack([best_arr, np.zeros((best_arr.shape[0], 72 - best_arr.shape[1]))])
                
                if clip.shape[0] >= self.seq_len: clip = clip[:self.seq_len, :]
                else: clip = np.vstack([clip, np.zeros((self.seq_len - clip.shape[0], 72))])
                
                return torch.from_numpy(clip.astype(np.float32)), label
        except:
            return torch.zeros((self.seq_len, 72), dtype=torch.float32), label

# ==========================================
# 3. æ‰«æç›®å½•
# ==========================================
def scan_directory(root_dir):
    labeled_list = []
    unlabeled_list = []
    
    print(f"ğŸ” æ­£åœ¨æ·±åº¦æ‰«ææ ¹ç›®å½•: {root_dir} ...")
    for folder_name in os.listdir(root_dir):
        folder_path = os.path.join(root_dir, folder_name)
        if not os.path.isdir(folder_path): continue
        
        is_unlabeled = (folder_name == 'others' or folder_name == 'tracking_general')
        label = -1
        
        if not is_unlabeled:
            if folder_name in LABEL_MAP:
                label = LABEL_MAP[folder_name]
            else:
                continue 
        
        for root, _, files in os.walk(folder_path):
            for f in files:
                if f.endswith('.npz'):
                    item = {'path': os.path.join(root, f), 'label': label}
                    if is_unlabeled:
                        unlabeled_list.append(item)
                    else:
                        labeled_list.append(item)
        
    print(f"âœ… æ‰«æå®Œæˆ!")
    print(f"   - å·²åˆ†ç±»æ ·æœ¬ (è®­ç»ƒé›†): {len(labeled_list)}")
    print(f"   - å¾…å¤„ç†æ ·æœ¬ (others): {len(unlabeled_list)}")
    return labeled_list, unlabeled_list

# ==========================================
# 4. æ¨¡å‹å®šä¹‰
# ==========================================
class MotionClassifier(nn.Module):
    def __init__(self, num_classes, input_dim=72, hidden_dim=128):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2)
        self.fc = nn.Linear(hidden_dim, num_classes)
        
    def forward(self, x):
        _, (h_n, _) = self.lstm(x)
        return self.fc(h_n[-1])

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    # --- è¯·ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„ ---
    ROOT_DIR = r"D:\amassdata\motions_by_type_1\motions_by_type_1" 
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    train_pool, candidate_pool = scan_directory(ROOT_DIR)
    
    if len(train_pool) == 0:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼")
        exit()

    history = {'pool_size': [len(train_pool)]}
    
    model = MotionClassifier(len(CLASS_NAMES)).to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    print(f"\nğŸš€ å¼€å§‹æš´åŠ›æ¬è¿è¿­ä»£ (å…± {MAX_ROUNDS} è½®)")
    print(f"ğŸ¯ ç›®æ ‡ï¼šæŠŠ others é‡Œçš„ {len(candidate_pool)} ä¸ªæ–‡ä»¶æ¬ç©ºï¼")

    # ================= å¾ªç¯è¿­ä»£ =================
    for round_idx in range(MAX_ROUNDS):
        # è®¡ç®—å½“å‰è½®æ¬¡çš„é˜ˆå€¼ (çº¿æ€§é€’å‡)
        current_threshold = START_CONF - (START_CONF - END_CONF) * (round_idx / MAX_ROUNDS)
        
        print(f"\n{'='*30}")
        print(f"ğŸ”„ Round {round_idx+1} / {MAX_ROUNDS}")
        print(f"âš™ï¸ å½“å‰ç½®ä¿¡åº¦é—¨æ§›: {current_threshold:.2f} (è¶Šä½æ¬å¾—è¶ŠçŒ›)")
        print(f"ğŸ“š å½“å‰è®­ç»ƒé›†è§„æ¨¡: {len(train_pool)}")
        print(f"ğŸ“¦ others å‰©ä½™æ–‡ä»¶: {len(candidate_pool)}")
        
        if len(candidate_pool) == 0:
            print("ğŸ‰ æ­å–œï¼others æ–‡ä»¶å¤¹å·²ç»è¢«æ¬ç©ºäº†ï¼")
            break

        # --- A. è®­ç»ƒé˜¶æ®µ ---
        train_ds = MemoryDataset(train_pool, seq_len=SEQ_LEN)
        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
        
        model.train()
        for epoch in range(EPOCHS_PER_ROUND):
            pbar = tqdm(train_loader, desc=f"   [è®­ç»ƒ] Ep {epoch+1}/{EPOCHS_PER_ROUND}", leave=False)
            for x, y in pbar:
                x, y = x.to(DEVICE), y.to(DEVICE)
                optimizer.zero_grad()
                logits = model(x)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()
                pbar.set_postfix({'loss': f"{loss.item():.4f}"})

        # --- B. æŒ–æ˜ä¸æ¬è¿é˜¶æ®µ ---
        print(f"   [æŒ–æ˜] æ­£åœ¨æ‰«æ others...")
        
        candidate_ds = MemoryDataset(candidate_pool, seq_len=SEQ_LEN)
        candidate_loader = DataLoader(candidate_ds, batch_size=BATCH_SIZE, shuffle=False)
        
        model.eval()
        new_labeled_samples = []
        remaining_candidates = []
        moved_count_this_round = 0
        
        with torch.no_grad():
            global_idx = 0
            for x, _ in tqdm(candidate_loader, desc="   [æ¬è¿ä¸­]"):
                x = x.to(DEVICE)
                logits = model(x)
                probs = torch.softmax(logits, dim=1)
                max_probs, preds = torch.max(probs, dim=1)
                
                for i in range(x.size(0)):
                    current_item = candidate_pool[global_idx]
                    prob = max_probs[i].item()
                    pred_label_idx = preds[i].item()
                    
                    if prob > current_threshold:
                        # === ç‰©ç†æ¬è¿ ===
                        target_folder_name = CLASS_NAMES[pred_label_idx]
                        target_dir = os.path.join(ROOT_DIR, target_folder_name)
                        
                        original_filename = os.path.basename(current_item['path'])
                        # åŠ ä¸Š auto_ å‰ç¼€æ–¹ä¾¿è¯†åˆ«
                        new_filename = f"auto_r{round_idx+1}_{original_filename}"
                        target_path = os.path.join(target_dir, new_filename)
                        
                        try:
                            # çœŸå®çš„ç‰©ç†ç§»åŠ¨ï¼
                            shutil.move(current_item['path'], target_path)
                            
                            # æ›´æ–°å†…å­˜çŠ¶æ€
                            current_item['label'] = pred_label_idx
                            current_item['path'] = target_path 
                            new_labeled_samples.append(current_item)
                            moved_count_this_round += 1
                            
                        except Exception as e:
                            # å¦‚æœæ¬è¿å¤±è´¥ï¼ˆæ¯”å¦‚æ–‡ä»¶å ç”¨ï¼‰ï¼Œå°±è·³è¿‡
                            remaining_candidates.append(current_item) 
                    else:
                        remaining_candidates.append(current_item)
                    
                    global_idx += 1
        
        # --- C. æ±‡æŠ¥æˆ˜æœ ---
        print(f"ğŸšš æœ¬è½®æˆåŠŸæ¬è¿: {moved_count_this_round} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“‰ others å‰©ä½™æ–‡ä»¶æ•°: {len(remaining_candidates)}")
        
        if moved_count_this_round == 0:
            print("âš ï¸ è­¦å‘Šï¼šæœ¬è½®æ²¡æœ‰æ¬èµ°ä»»ä½•æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯é˜ˆå€¼å¤ªé«˜æˆ–æ¨¡å‹å­¦ä¸åŠ¨äº†ã€‚")
            if current_threshold <= END_CONF:
                 print("ğŸ›‘ å·²è¾¾åˆ°æœ€ä½é˜ˆå€¼ä¸”æ— æ–°æ ·æœ¬ï¼Œå¼ºè¡Œç»“æŸã€‚")
                 break
            
        train_pool.extend(new_labeled_samples)
        candidate_pool = remaining_candidates
        history['pool_size'].append(len(train_pool))

    print("\nâœ… æ‰€æœ‰è¿­ä»£å®Œæˆï¼")
    print("å¿«å» others æ–‡ä»¶å¤¹çœ‹çœ‹æ˜¯ä¸æ˜¯ç©ºäº†ï¼")